{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------------------------\n",
    "## Summary : perform parsing using tree parser\n",
    "## Author  : Srinivas Venkata Vemparala\n",
    "## Source  : https://github.com/neubig/nn4nlp-code\n",
    "##---------------------------------------------------------------------------------\n",
    "\n",
    "# paper : http://aclweb.org/anthology/P/P15/P15-1150.pdf\n",
    "\n",
    "import codecs\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# methods to extract the tree from the file\n",
    "\n",
    "# tokenize the line\n",
    "def _tokenize_sexpr(s):\n",
    "    tokker = re.compile(r\" +|[()]|[^ ()]+\")\n",
    "    toks = [t for t in [match.group(0) for match in tokker.finditer(s)] if t[0] != \" \"]\n",
    "    \n",
    "    return toks\n",
    "\n",
    "# get the stuff in the brackets\n",
    "def _within_bracket(toks):\n",
    "    label = next(toks)\n",
    "    children = []\n",
    "\n",
    "    for tok in toks:\n",
    "        if tok == \"(\":\n",
    "            children.append(_within_bracket(toks))\n",
    "        elif tok == \")\":\n",
    "            return Tree(label, children)\n",
    "        else: \n",
    "            children.append(Tree(tok, None))\n",
    "            \n",
    "    assert(False),list(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the tree class\n",
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self, label, children=None):\n",
    "        self.label = label\n",
    "        self.children = children\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_sexpr(string):\n",
    "        toks = iter(_tokenize_sexpr(string))\n",
    "        assert next(toks) == \"(\"\n",
    "        return _within_bracket(toks)\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.children is None: return self.label\n",
    "        return \"[%s %s]\" % (self.label, \" \".join([str(c) for c in self.children]))\n",
    "\n",
    "    def isleaf(self): \n",
    "        return self.children==None\n",
    "    \n",
    "    def leaves_iter(self):\n",
    "        if self.isleaf():\n",
    "            yield self\n",
    "        else:\n",
    "            for c in self.children:\n",
    "                for l in c.leaves_iter(): \n",
    "                    yield l\n",
    "\n",
    "    def leaves(self): \n",
    "        return list(self.leaves_iter())\n",
    "\n",
    "    \n",
    "    def nonterms_iter(self):\n",
    "        if not self.isleaf():\n",
    "            yield self\n",
    "            for c in self.children:\n",
    "                for n in c.nonterms_iter():\n",
    "                    yield n\n",
    "          \n",
    "    def nonterms(self): \n",
    "        return list(self.nonterms_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to read the dataset\n",
    "def read_dataset(filename):\n",
    "    return [Tree.from_sexpr(line.strip()) for line in codecs.open(filename,\"r\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to get the vocabulary and convert it to int and back to words\n",
    "def get_vocabs(trees):\n",
    "    label_vocab = Counter()\n",
    "    word_vocab  = Counter()\n",
    "    \n",
    "    for tree in trees:\n",
    "        label_vocab.update([n.label for n in tree.nonterms()])\n",
    "        word_vocab.update([l.label for l in tree.leaves()])\n",
    "        \n",
    "    labels = [x for x,c in label_vocab.items() if c > 0]\n",
    "    words  = [\"_UNK_\"] + [x for x,c in word_vocab.items() if c > 0]\n",
    "    \n",
    "    l2i = {l:i for i,l in enumerate(labels)}\n",
    "    w2i = {w:i for i,w in enumerate(words)}\n",
    "\n",
    "    return l2i, w2i, labels, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the training and dev data\n",
    "train = read_dataset(\"../data/parsing/trees/train.txt\")\n",
    "dev = read_dataset(\"../data/parsing/trees/dev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words :  18281\n",
      "number of tags :  5\n"
     ]
    }
   ],
   "source": [
    "l2i, w2i, i2l, i2w = get_vocabs(train)\n",
    "\n",
    "ntags = len(l2i)\n",
    "nwords = len(w2i)\n",
    "\n",
    "print('number of words : ',nwords)\n",
    "print('number of tags : ',ntags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets define a the Tree RNN described in the paper\n",
    "# normal RNN\n",
    "class TreeRNNBuilder(object):\n",
    "    \n",
    "    def __init__(self, model, word_vocab, hdim):\n",
    "        self.W = model.add_parameters((hdim, 2*hdim))\n",
    "        self.E = model.add_lookup_parameters((len(word_vocab),hdim))\n",
    "        self.w2i = word_vocab\n",
    "    \n",
    "    def expr_for_tree(self, tree):\n",
    "        # if we are looking at leaf   \n",
    "        if tree.isleaf():\n",
    "            return self.E[self.w2i.get(tree.label,0)]\n",
    "\n",
    "        # if the tree has only one child then that child must be leaf\n",
    "        if len(tree.children) == 1:\n",
    "            assert(tree.children[0].isleaf())\n",
    "            expr = self.expr_for_tree(tree.children[0])\n",
    "\n",
    "            return expr\n",
    "        \n",
    "        # if the tree has two children\n",
    "        assert(len(tree.children) == 2),tree.children[0]\n",
    "        e1 = self.expr_for_tree(tree.children[0])\n",
    "        e2 = self.expr_for_tree(tree.children[1])\n",
    "        W = dy.parameter(self.W)\n",
    "        expr = dy.tanh(W*dy.concatenate([e1,e2]))\n",
    "\n",
    "        return expr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN with the LSTM structure\n",
    "class TreeLSTMBuilder(object):\n",
    "\n",
    "    def __init__(self, model, word_vocab, wdim, hdim):\n",
    "        self.WS = [model.add_parameters((hdim, wdim)) for _ in \"iou\"]    # input output update\n",
    "        self.US = [model.add_parameters((hdim, 2*hdim)) for _ in \"iou\"]  # input output update\n",
    "        self.UFS =[model.add_parameters((hdim, hdim)) for _ in \"ff\"]     # forget gate\n",
    "        self.BS = [model.add_parameters(hdim) for _ in \"iouf\"]           # input output update and forget\n",
    "        self.E = model.add_lookup_parameters((len(word_vocab),wdim))\n",
    "        self.w2i = word_vocab\n",
    "\n",
    "\n",
    "\n",
    "    def expr_for_tree(self, tree):\n",
    "        # if we are looking at leaf  \n",
    "        if tree.isleaf():\n",
    "            return self.E[self.w2i.get(tree.label,0)]\n",
    "        \n",
    "        # if the tree has only one child then that child must be leaf\n",
    "        if len(tree.children) == 1:\n",
    "            assert(tree.children[0].isleaf())\n",
    "            emb = self.expr_for_tree(tree.children[0])\n",
    "            Wi,Wo,Wu   = [dy.parameter(w) for w in self.WS]\n",
    "            bi,bo,bu,_ = [dy.parameter(b) for b in self.BS]\n",
    "\n",
    "            i = dy.logistic(Wi*emb + bi)\n",
    "            o = dy.logistic(Wo*emb + bo)\n",
    "            u = dy.tanh(    Wu*emb + bu)\n",
    "            c = dy.cmult(i,u)\n",
    "\n",
    "            expr = dy.cmult(o,dy.tanh(c))\n",
    "            return expr\n",
    "\n",
    "        # if the tree has two children\n",
    "        assert(len(tree.children) == 2),tree.children[0]\n",
    "        e1 = self.expr_for_tree(tree.children[0])\n",
    "        e2 = self.expr_for_tree(tree.children[1])\n",
    "        Ui,Uo,Uu = [dy.parameter(u) for u in self.US]\n",
    "        Uf1,Uf2 = [dy.parameter(u) for u in self.UFS]\n",
    "        bi,bo,bu,bf = [dy.parameter(b) for b in self.BS]\n",
    "        e = dy.concatenate([e1,e2])\n",
    "        i = dy.logistic(Ui*e + bi)\n",
    "        o = dy.logistic(Uo*e + bo)\n",
    "        f1 = dy.logistic(Uf1*e1 + bf)\n",
    "        f2 = dy.logistic(Uf2*e2 + bf)\n",
    "        u = dy.tanh(    Uu*e + bu)\n",
    "        c = dy.cmult(i,u) + dy.cmult(f1,e1) + dy.cmult(f2,e2)\n",
    "        h = dy.cmult(o,dy.tanh(c))\n",
    "        expr = h\n",
    "\n",
    "        return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets define the model and the optimizer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)\n",
    "\n",
    "# lets define the Hiddenlayer size and embedding size\n",
    "EMB_SIZE = 64\n",
    "HID_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets first execute the childsum LSTM\n",
    "builder = TreeRNNBuilder(model, w2i, HID_SIZE)\n",
    "\n",
    "W_sm = model.add_parameters((ntags, HID_SIZE))        # Softmax weights\n",
    "b_sm = model.add_parameters((ntags))                  # Softmax bias\n",
    "\n",
    "\n",
    "# lets write a method to compute the scores \n",
    "def computeScores(tree):\n",
    "    # renew the computation graph\n",
    "    dy.renew_cg()\n",
    "    \n",
    "    # get the embedding\n",
    "    emb = builder.expr_for_tree(tree)\n",
    "    \n",
    "    # get the softmax weights into the cg\n",
    "    weights = dy.parameter(W_sm)\n",
    "    biases = dy.parameter(b_sm)\n",
    "    \n",
    "    return weights*emb+biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training .....\n",
      "Train_loss at iter :  0  is  2.0867597297782756e-05 . Time taken :  1.0637664794921875\n",
      "Test_Accuracy at iter :  0  is  0.26612170753860126 . Time taken :  0.560774564743042\n",
      "Train_loss at iter :  1  is  0.0 . Time taken :  0.8954987525939941\n",
      "Test_Accuracy at iter :  1  is  0.2652134423251589 . Time taken :  0.5678150653839111\n",
      "Train_loss at iter :  2  is  0.00044717195998416855 . Time taken :  0.8768372535705566\n",
      "Test_Accuracy at iter :  2  is  0.2652134423251589 . Time taken :  0.5650622844696045\n",
      "Train_loss at iter :  3  is  0.0004942372497101402 . Time taken :  0.874129056930542\n",
      "Test_Accuracy at iter :  3  is  0.2670299727520436 . Time taken :  0.5331592559814453\n",
      "Train_loss at iter :  4  is  0.00029265615489152487 . Time taken :  0.8747680187225342\n",
      "Test_Accuracy at iter :  4  is  0.2670299727520436 . Time taken :  0.5432217121124268\n",
      "Train_loss at iter :  5  is  0.0006952050808217195 . Time taken :  0.8548574447631836\n",
      "Test_Accuracy at iter :  5  is  0.2652134423251589 . Time taken :  0.5440165996551514\n",
      "Train_loss at iter :  6  is  3.074173735322131e-05 . Time taken :  0.8565216064453125\n",
      "Test_Accuracy at iter :  6  is  0.2633969118982743 . Time taken :  0.5370407104492188\n",
      "Train_loss at iter :  7  is  8.601513917972979e-07 . Time taken :  0.8412199020385742\n",
      "Test_Accuracy at iter :  7  is  0.26430517711171664 . Time taken :  0.5492870807647705\n",
      "Train_loss at iter :  8  is  0.0003643755832414949 . Time taken :  0.9263472557067871\n",
      "Test_Accuracy at iter :  8  is  0.2633969118982743 . Time taken :  0.6105256080627441\n",
      "Train_loss at iter :  9  is  0.00041774702206086577 . Time taken :  1.0192625522613525\n",
      "Test_Accuracy at iter :  9  is  0.2633969118982743 . Time taken :  0.6133303642272949\n",
      "Train_loss at iter :  10  is  0.000753833225157377 . Time taken :  1.0793464183807373\n",
      "Test_Accuracy at iter :  10  is  0.26430517711171664 . Time taken :  0.6093721389770508\n",
      "Train_loss at iter :  11  is  0.00036288362540555806 . Time taken :  1.0932695865631104\n",
      "Test_Accuracy at iter :  11  is  0.26248864668483196 . Time taken :  0.8593716621398926\n",
      "Train_loss at iter :  12  is  0.0004655176613214757 . Time taken :  1.3125038146972656\n",
      "Test_Accuracy at iter :  12  is  0.2615803814713896 . Time taken :  0.6048271656036377\n",
      "Train_loss at iter :  13  is  0.000625382201948416 . Time taken :  1.1442909240722656\n",
      "Test_Accuracy at iter :  13  is  0.2633969118982743 . Time taken :  0.5312445163726807\n",
      "Train_loss at iter :  14  is  0.000500647427883934 . Time taken :  0.9062373638153076\n",
      "Test_Accuracy at iter :  14  is  0.26430517711171664 . Time taken :  0.5312483310699463\n",
      "Train_loss at iter :  15  is  0.0005459695049885953 . Time taken :  0.8594181537628174\n",
      "Test_Accuracy at iter :  15  is  0.26248864668483196 . Time taken :  0.5312440395355225\n",
      "Train_loss at iter :  16  is  0.0007797854111882185 . Time taken :  0.859320878982544\n",
      "Test_Accuracy at iter :  16  is  0.26248864668483196 . Time taken :  0.5312464237213135\n",
      "Train_loss at iter :  17  is  4.796401252237598e-05 . Time taken :  0.8437502384185791\n",
      "Test_Accuracy at iter :  17  is  0.26430517711171664 . Time taken :  0.5468742847442627\n",
      "Train_loss at iter :  18  is  0.0003112069564812192 . Time taken :  0.9062509536743164\n",
      "Test_Accuracy at iter :  18  is  0.26612170753860126 . Time taken :  0.5624964237213135\n",
      "Train_loss at iter :  19  is  0.0004946922653176812 . Time taken :  0.9531261920928955\n",
      "Test_Accuracy at iter :  19  is  0.2652134423251589 . Time taken :  0.5625383853912354\n",
      "Train_loss at iter :  20  is  0.0004454665862665641 . Time taken :  0.9062151908874512\n",
      "Test_Accuracy at iter :  20  is  0.2652134423251589 . Time taken :  0.5469131469726562\n",
      "Train_loss at iter :  21  is  0.0 . Time taken :  0.8437085151672363\n",
      "Test_Accuracy at iter :  21  is  0.26430517711171664 . Time taken :  0.5312466621398926\n",
      "Train_loss at iter :  22  is  0.00011044631150554629 . Time taken :  0.9062864780426025\n",
      "Test_Accuracy at iter :  22  is  0.26612170753860126 . Time taken :  0.5781307220458984\n",
      "Train_loss at iter :  23  is  8.389388633131534e-05 . Time taken :  0.9062676429748535\n",
      "Test_Accuracy at iter :  23  is  0.26248864668483196 . Time taken :  0.5468177795410156\n",
      "Train_loss at iter :  24  is  0.0007918833681706632 . Time taken :  0.9062907695770264\n",
      "Test_Accuracy at iter :  24  is  0.26248864668483196 . Time taken :  0.5780894756317139\n",
      "Train_loss at iter :  25  is  0.0006388531865252091 . Time taken :  0.8906676769256592\n",
      "Test_Accuracy at iter :  25  is  0.26248864668483196 . Time taken :  0.5624556541442871\n",
      "Train_loss at iter :  26  is  0.0005491017067477051 . Time taken :  0.875\n",
      "Test_Accuracy at iter :  26  is  0.2633969118982743 . Time taken :  0.5781240463256836\n",
      "Train_loss at iter :  27  is  0.00040086941995870755 . Time taken :  0.8906610012054443\n",
      "Test_Accuracy at iter :  27  is  0.26430517711171664 . Time taken :  0.5780787467956543\n",
      "Train_loss at iter :  28  is  0.0004518595471810759 . Time taken :  0.9687538146972656\n",
      "Test_Accuracy at iter :  28  is  0.2652134423251589 . Time taken :  0.6250007152557373\n",
      "Train_loss at iter :  29  is  0.00026234738835681243 . Time taken :  0.8750050067901611\n",
      "Test_Accuracy at iter :  29  is  0.26430517711171664 . Time taken :  0.5468661785125732\n",
      "Train_loss at iter :  30  is  0.000724457846152202 . Time taken :  0.9062073230743408\n",
      "Test_Accuracy at iter :  30  is  0.2652134423251589 . Time taken :  0.5468757152557373\n",
      "Train_loss at iter :  31  is  0.0005091595627395401 . Time taken :  0.9219093322753906\n",
      "Test_Accuracy at iter :  31  is  0.2652134423251589 . Time taken :  0.5781290531158447\n",
      "Train_loss at iter :  32  is  0.00014957120076993877 . Time taken :  0.9062552452087402\n",
      "Test_Accuracy at iter :  32  is  0.2652134423251589 . Time taken :  0.5468313694000244\n",
      "Train_loss at iter :  33  is  0.0009236469697416498 . Time taken :  0.9062526226043701\n",
      "Test_Accuracy at iter :  33  is  0.26248864668483196 . Time taken :  0.5625412464141846\n",
      "Train_loss at iter :  34  is  0.0006238265653674522 . Time taken :  0.9218356609344482\n",
      "Test_Accuracy at iter :  34  is  0.26430517711171664 . Time taken :  0.546870231628418\n",
      "Train_loss at iter :  35  is  0.000497987207848481 . Time taken :  0.9375419616699219\n",
      "Test_Accuracy at iter :  35  is  0.26430517711171664 . Time taken :  0.5780806541442871\n",
      "Train_loss at iter :  36  is  0.0005044258489144428 . Time taken :  0.9062483310699463\n",
      "Test_Accuracy at iter :  36  is  0.2633969118982743 . Time taken :  0.5625033378601074\n",
      "Train_loss at iter :  37  is  0.0008477179075448254 . Time taken :  0.9219074249267578\n",
      "Test_Accuracy at iter :  37  is  0.2652134423251589 . Time taken :  0.5624709129333496\n",
      "Train_loss at iter :  38  is  0.0005290098627854823 . Time taken :  0.921910285949707\n",
      "Test_Accuracy at iter :  38  is  0.2615803814713896 . Time taken :  0.5780854225158691\n",
      "Train_loss at iter :  39  is  0.00012186180786247111 . Time taken :  0.9374990463256836\n",
      "Test_Accuracy at iter :  39  is  0.259763851044505 . Time taken :  0.5781233310699463\n",
      "Train_loss at iter :  40  is  0.0002538980951023459 . Time taken :  0.9219205379486084\n",
      "Test_Accuracy at iter :  40  is  0.25885558583106266 . Time taken :  0.5468316078186035\n",
      "Train_loss at iter :  41  is  0.0001455544588271152 . Time taken :  0.9531638622283936\n",
      "Test_Accuracy at iter :  41  is  0.259763851044505 . Time taken :  0.5468344688415527\n",
      "Train_loss at iter :  42  is  0.0008197299550088603 . Time taken :  0.8750050067901611\n",
      "Test_Accuracy at iter :  42  is  0.26248864668483196 . Time taken :  0.5468347072601318\n",
      "Train_loss at iter :  43  is  0.0009909860427013497 . Time taken :  0.9219427108764648\n",
      "Test_Accuracy at iter :  43  is  0.26430517711171664 . Time taken :  0.5468456745147705\n",
      "Train_loss at iter :  44  is  0.0009117836920956101 . Time taken :  0.9531412124633789\n",
      "Test_Accuracy at iter :  44  is  0.2633969118982743 . Time taken :  0.546823263168335\n",
      "Train_loss at iter :  45  is  0.0005417453327428982 . Time taken :  0.8750014305114746\n",
      "Test_Accuracy at iter :  45  is  0.26612170753860126 . Time taken :  0.5312442779541016\n",
      "Train_loss at iter :  46  is  0.0 . Time taken :  0.8750040531158447\n",
      "Test_Accuracy at iter :  46  is  0.2615803814713896 . Time taken :  0.5312485694885254\n",
      "Train_loss at iter :  47  is  0.000521512067273315 . Time taken :  0.8906245231628418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Accuracy at iter :  47  is  0.26067211625794734 . Time taken :  0.5312485694885254\n",
      "Train_loss at iter :  48  is  3.3446179514520624e-05 . Time taken :  0.8750247955322266\n",
      "Test_Accuracy at iter :  48  is  0.259763851044505 . Time taken :  0.562518835067749\n",
      "Train_loss at iter :  49  is  0.00018073844440867393 . Time taken :  1.0788524150848389\n",
      "Test_Accuracy at iter :  49  is  0.2579473206176203 . Time taken :  0.5468764305114746\n",
      "Train_loss at iter :  50  is  0.0005818571379122217 . Time taken :  0.875009298324585\n",
      "Test_Accuracy at iter :  50  is  0.25522252497729336 . Time taken :  0.919074535369873\n",
      "Train_loss at iter :  51  is  0.00014023071203785444 . Time taken :  0.9343366622924805\n",
      "Test_Accuracy at iter :  51  is  0.2579473206176203 . Time taken :  0.6249997615814209\n",
      "Train_loss at iter :  52  is  0.00033862997641724145 . Time taken :  1.4417426586151123\n",
      "Test_Accuracy at iter :  52  is  0.25885558583106266 . Time taken :  0.8760025501251221\n",
      "Train_loss at iter :  53  is  0.0005947646688432729 . Time taken :  2.0639991760253906\n",
      "Test_Accuracy at iter :  53  is  0.25885558583106266 . Time taken :  1.3335750102996826\n",
      "Train_loss at iter :  54  is  0.0007081660773423727 . Time taken :  2.366575241088867\n",
      "Test_Accuracy at iter :  54  is  0.25885558583106266 . Time taken :  0.5861198902130127\n",
      "Train_loss at iter :  55  is  0.00018933804684810425 . Time taken :  1.21966552734375\n",
      "Test_Accuracy at iter :  55  is  0.26067211625794734 . Time taken :  0.7141525745391846\n",
      "Train_loss at iter :  56  is  0.00028020057004042776 . Time taken :  1.1391386985778809\n",
      "Test_Accuracy at iter :  56  is  0.2633969118982743 . Time taken :  0.7159750461578369\n",
      "Train_loss at iter :  57  is  0.00021103952317202135 . Time taken :  1.1739768981933594\n",
      "Test_Accuracy at iter :  57  is  0.2652134423251589 . Time taken :  0.7395744323730469\n",
      "Train_loss at iter :  58  is  0.00017567143569724837 . Time taken :  1.2594859600067139\n",
      "Test_Accuracy at iter :  58  is  0.2652134423251589 . Time taken :  0.6766581535339355\n",
      "Train_loss at iter :  59  is  0.00014338112167651287 . Time taken :  1.1578752994537354\n",
      "Test_Accuracy at iter :  59  is  0.2688465031789282 . Time taken :  0.6697595119476318\n",
      "Train_loss at iter :  60  is  0.0007189430770802587 . Time taken :  1.1636090278625488\n",
      "Test_Accuracy at iter :  60  is  0.26612170753860126 . Time taken :  0.6498174667358398\n",
      "Train_loss at iter :  61  is  0.000850228781110785 . Time taken :  1.1760339736938477\n",
      "Test_Accuracy at iter :  61  is  0.26793823796548594 . Time taken :  0.6535704135894775\n",
      "Train_loss at iter :  62  is  0.00022570155421446325 . Time taken :  1.1797175407409668\n",
      "Test_Accuracy at iter :  62  is  0.26975476839237056 . Time taken :  0.6736092567443848\n",
      "Train_loss at iter :  63  is  0.00015124453978145614 . Time taken :  1.158304214477539\n",
      "Test_Accuracy at iter :  63  is  0.26793823796548594 . Time taken :  0.706611156463623\n",
      "Train_loss at iter :  64  is  0.0008095005589924502 . Time taken :  1.2701210975646973\n",
      "Test_Accuracy at iter :  64  is  0.26612170753860126 . Time taken :  0.6541562080383301\n",
      "Train_loss at iter :  65  is  0.0007545545083306701 . Time taken :  1.2190096378326416\n",
      "Test_Accuracy at iter :  65  is  0.26612170753860126 . Time taken :  0.7005679607391357\n",
      "Train_loss at iter :  66  is  0.0009915986087884795 . Time taken :  1.1805179119110107\n",
      "Test_Accuracy at iter :  66  is  0.26612170753860126 . Time taken :  0.6696250438690186\n",
      "Train_loss at iter :  67  is  0.00015982543205500543 . Time taken :  1.1835582256317139\n",
      "Test_Accuracy at iter :  67  is  0.26430517711171664 . Time taken :  0.6592402458190918\n",
      "Train_loss at iter :  68  is  0.0006186007783654031 . Time taken :  1.0835344791412354\n",
      "Test_Accuracy at iter :  68  is  0.2615803814713896 . Time taken :  0.6462631225585938\n",
      "Train_loss at iter :  69  is  0.00022560835219501108 . Time taken :  1.0797295570373535\n",
      "Test_Accuracy at iter :  69  is  0.26430517711171664 . Time taken :  0.6137399673461914\n",
      "Train_loss at iter :  70  is  0.0006318270936887363 . Time taken :  1.0663208961486816\n",
      "Test_Accuracy at iter :  70  is  0.26612170753860126 . Time taken :  0.6036059856414795\n",
      "Train_loss at iter :  71  is  0.0007411407285861755 . Time taken :  1.0335981845855713\n",
      "Test_Accuracy at iter :  71  is  0.2652134423251589 . Time taken :  0.6102588176727295\n",
      "Train_loss at iter :  72  is  0.00043036671501866885 . Time taken :  1.009493350982666\n",
      "Test_Accuracy at iter :  72  is  0.2633969118982743 . Time taken :  0.6079874038696289\n",
      "Train_loss at iter :  73  is  0.0009283541740103161 . Time taken :  1.0406711101531982\n",
      "Test_Accuracy at iter :  73  is  0.2615803814713896 . Time taken :  0.604456901550293\n",
      "Train_loss at iter :  74  is  0.0004807354582382945 . Time taken :  1.0389556884765625\n",
      "Test_Accuracy at iter :  74  is  0.26248864668483196 . Time taken :  0.6016092300415039\n",
      "Train_loss at iter :  75  is  0.0006577806749593899 . Time taken :  0.9997954368591309\n",
      "Test_Accuracy at iter :  75  is  0.2615803814713896 . Time taken :  0.6159563064575195\n",
      "Train_loss at iter :  76  is  0.00027514514181944315 . Time taken :  1.126030683517456\n",
      "Test_Accuracy at iter :  76  is  0.26430517711171664 . Time taken :  0.6529228687286377\n",
      "Train_loss at iter :  77  is  0.0005770409375094296 . Time taken :  1.0951323509216309\n",
      "Test_Accuracy at iter :  77  is  0.26793823796548594 . Time taken :  0.625206708908081\n",
      "Train_loss at iter :  78  is  0.0005228254902228881 . Time taken :  1.1034116744995117\n",
      "Test_Accuracy at iter :  78  is  0.26975476839237056 . Time taken :  0.630962610244751\n",
      "Train_loss at iter :  79  is  0.0005127205495977223 . Time taken :  1.0799891948699951\n",
      "Test_Accuracy at iter :  79  is  0.2670299727520436 . Time taken :  0.6385319232940674\n",
      "Train_loss at iter :  80  is  0.0008239976029271043 . Time taken :  1.0578291416168213\n",
      "Test_Accuracy at iter :  80  is  0.27157129881925524 . Time taken :  0.650015115737915\n",
      "Train_loss at iter :  81  is  0.00047489336590641893 . Time taken :  1.1196796894073486\n",
      "Test_Accuracy at iter :  81  is  0.27157129881925524 . Time taken :  0.6205360889434814\n",
      "Train_loss at iter :  82  is  0.00041546329353632554 . Time taken :  1.0862512588500977\n",
      "Test_Accuracy at iter :  82  is  0.26975476839237056 . Time taken :  0.6136898994445801\n",
      "Train_loss at iter :  83  is  0.00013467236962657743 . Time taken :  1.0064480304718018\n",
      "Test_Accuracy at iter :  83  is  0.27338782924613986 . Time taken :  0.5936605930328369\n",
      "Train_loss at iter :  84  is  0.0004071526871191875 . Time taken :  1.0307459831237793\n",
      "Test_Accuracy at iter :  84  is  0.2706630336058129 . Time taken :  0.5850765705108643\n",
      "Train_loss at iter :  85  is  0.0005519390106201172 . Time taken :  1.0666203498840332\n",
      "Test_Accuracy at iter :  85  is  0.27520435967302453 . Time taken :  0.6188497543334961\n",
      "Train_loss at iter :  86  is  0.0007158827580762713 . Time taken :  1.0174660682678223\n",
      "Test_Accuracy at iter :  86  is  0.2724795640326976 . Time taken :  0.5903277397155762\n",
      "Train_loss at iter :  87  is  4.552395435308249e-05 . Time taken :  1.0493566989898682\n",
      "Test_Accuracy at iter :  87  is  0.26975476839237056 . Time taken :  0.6998922824859619\n",
      "Train_loss at iter :  88  is  0.00048291638549347493 . Time taken :  1.1049644947052002\n",
      "Test_Accuracy at iter :  88  is  0.2688465031789282 . Time taken :  0.6691789627075195\n",
      "Train_loss at iter :  89  is  5.110609955555491e-05 . Time taken :  1.1300711631774902\n",
      "Test_Accuracy at iter :  89  is  0.26975476839237056 . Time taken :  0.6498966217041016\n",
      "Train_loss at iter :  90  is  0.0 . Time taken :  1.166226863861084\n",
      "Test_Accuracy at iter :  90  is  0.2652134423251589 . Time taken :  0.6834547519683838\n",
      "Train_loss at iter :  91  is  0.00012286208318860344 . Time taken :  1.1179988384246826\n",
      "Test_Accuracy at iter :  91  is  0.26248864668483196 . Time taken :  0.6717450618743896\n",
      "Train_loss at iter :  92  is  0.0002293719836835111 . Time taken :  0.9931955337524414\n",
      "Test_Accuracy at iter :  92  is  0.2633969118982743 . Time taken :  0.6069762706756592\n",
      "Train_loss at iter :  93  is  0.0 . Time taken :  1.016648769378662\n",
      "Test_Accuracy at iter :  93  is  0.26430517711171664 . Time taken :  0.6133971214294434\n",
      "Train_loss at iter :  94  is  0.00011283270177546513 . Time taken :  1.003999948501587\n",
      "Test_Accuracy at iter :  94  is  0.26612170753860126 . Time taken :  0.6057636737823486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss at iter :  95  is  2.3444514540250828e-05 . Time taken :  1.0094079971313477\n",
      "Test_Accuracy at iter :  95  is  0.2670299727520436 . Time taken :  0.5968325138092041\n",
      "Train_loss at iter :  96  is  1.4973043948970037e-05 . Time taken :  1.0244693756103516\n",
      "Test_Accuracy at iter :  96  is  0.2670299727520436 . Time taken :  0.6037271022796631\n",
      "Train_loss at iter :  97  is  0.00035746270016338047 . Time taken :  1.010801076889038\n",
      "Test_Accuracy at iter :  97  is  0.26430517711171664 . Time taken :  0.6096444129943848\n",
      "Train_loss at iter :  98  is  0.0006299770615074072 . Time taken :  1.0105443000793457\n",
      "Test_Accuracy at iter :  98  is  0.26430517711171664 . Time taken :  0.5954718589782715\n",
      "Train_loss at iter :  99  is  9.908986169747199e-05 . Time taken :  1.1234097480773926\n",
      "Test_Accuracy at iter :  99  is  0.26612170753860126 . Time taken :  0.6000771522521973\n"
     ]
    }
   ],
   "source": [
    "# lets perform Training\n",
    "print('Started Training .....')\n",
    "\n",
    "for i in range(100):\n",
    "    # randomly shuffle the training examples\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    trainLoss = 0\n",
    "    startTime = time.time()\n",
    "    for tree in train:\n",
    "        myLoss = dy.hinge(computeScores(tree), l2i[tree.label]) # can pick neg logsoftmaxloss also\n",
    "        \n",
    "    trainLoss += myLoss.value()\n",
    "    myLoss.backward()\n",
    "    trainer.update()\n",
    "    print(\"Train_loss at iter : \",i,\" is \",trainLoss/len(train),'. Time taken : ',(-startTime+time.time()))\n",
    "    \n",
    "    startTime = time.time()\n",
    "    correct = 0\n",
    "    for tree in dev:\n",
    "        scores = computeScores(tree).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        if(predict==l2i[tree.label]):\n",
    "            correct += 1\n",
    "    print(\"Test_Accuracy at iter : \",i,\" is \",correct/len(dev),'. Time taken : ',(-startTime+time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training .....\n",
      "Train_loss at iter :  0  is  0.0005263689528690295 . Time taken :  10.181970834732056\n",
      "Test_Accuracy at iter :  0  is  0.26248864668483196 . Time taken :  3.2994637489318848\n",
      "Train_loss at iter :  1  is  0.0008902569835105639 . Time taken :  10.508680820465088\n",
      "Test_Accuracy at iter :  1  is  0.26248864668483196 . Time taken :  3.0892579555511475\n",
      "Train_loss at iter :  2  is  0.0008759815594676729 . Time taken :  10.083086252212524\n",
      "Test_Accuracy at iter :  2  is  0.26248864668483196 . Time taken :  3.188868761062622\n",
      "Train_loss at iter :  3  is  0.0005096780896633305 . Time taken :  10.141981363296509\n",
      "Test_Accuracy at iter :  3  is  0.26248864668483196 . Time taken :  3.099905252456665\n",
      "Train_loss at iter :  4  is  0.00019126700774560706 . Time taken :  10.164716720581055\n",
      "Test_Accuracy at iter :  4  is  0.26248864668483196 . Time taken :  3.0974981784820557\n",
      "Train_loss at iter :  5  is  0.00019399816177311015 . Time taken :  10.246028184890747\n",
      "Test_Accuracy at iter :  5  is  0.26248864668483196 . Time taken :  3.102510452270508\n",
      "Train_loss at iter :  6  is  0.0005452752336580655 . Time taken :  10.136049270629883\n",
      "Test_Accuracy at iter :  6  is  0.26248864668483196 . Time taken :  3.1169543266296387\n",
      "Train_loss at iter :  7  is  0.0005405289626746588 . Time taken :  10.16198205947876\n",
      "Test_Accuracy at iter :  7  is  0.26248864668483196 . Time taken :  3.1000967025756836\n",
      "Train_loss at iter :  8  is  0.0002992673871222507 . Time taken :  10.279426574707031\n",
      "Test_Accuracy at iter :  8  is  0.26248864668483196 . Time taken :  3.097642421722412\n",
      "Train_loss at iter :  9  is  0.0005517488115289238 . Time taken :  10.094468116760254\n",
      "Test_Accuracy at iter :  9  is  0.26248864668483196 . Time taken :  3.0996298789978027\n",
      "Train_loss at iter :  10  is  0.0005387916100605596 . Time taken :  7.847659111022949\n",
      "Test_Accuracy at iter :  10  is  0.26248864668483196 . Time taken :  2.7414662837982178\n",
      "Train_loss at iter :  11  is  0.0001914999709370431 . Time taken :  10.391730785369873\n",
      "Test_Accuracy at iter :  11  is  0.26248864668483196 . Time taken :  3.2401201725006104\n",
      "Train_loss at iter :  12  is  0.00018370218491286375 . Time taken :  10.34523320198059\n",
      "Test_Accuracy at iter :  12  is  0.26248864668483196 . Time taken :  3.2041308879852295\n",
      "Train_loss at iter :  13  is  0.0005065415905655994 . Time taken :  9.587321519851685\n",
      "Test_Accuracy at iter :  13  is  0.26248864668483196 . Time taken :  2.5294711589813232\n",
      "Train_loss at iter :  14  is  0.000178992971498868 . Time taken :  9.74002718925476\n",
      "Test_Accuracy at iter :  14  is  0.26248864668483196 . Time taken :  3.1151046752929688\n",
      "Train_loss at iter :  15  is  0.000851126422596335 . Time taken :  10.04659366607666\n",
      "Test_Accuracy at iter :  15  is  0.26248864668483196 . Time taken :  3.1297800540924072\n",
      "Train_loss at iter :  16  is  0.0005130144987213478 . Time taken :  9.931413650512695\n",
      "Test_Accuracy at iter :  16  is  0.26248864668483196 . Time taken :  3.1818034648895264\n",
      "Train_loss at iter :  17  is  0.0004937587382641624 . Time taken :  10.200098037719727\n",
      "Test_Accuracy at iter :  17  is  0.26248864668483196 . Time taken :  3.233236312866211\n",
      "Train_loss at iter :  18  is  0.0005048591545905067 . Time taken :  10.398183822631836\n",
      "Test_Accuracy at iter :  18  is  0.26248864668483196 . Time taken :  3.2022294998168945\n",
      "Train_loss at iter :  19  is  0.0001699792758355873 . Time taken :  10.167419910430908\n",
      "Test_Accuracy at iter :  19  is  0.26248864668483196 . Time taken :  2.9461870193481445\n",
      "Train_loss at iter :  20  is  0.00016123773565006612 . Time taken :  10.240505456924438\n",
      "Test_Accuracy at iter :  20  is  0.26248864668483196 . Time taken :  3.0334012508392334\n",
      "Train_loss at iter :  21  is  0.000377912088279867 . Time taken :  10.361780166625977\n",
      "Test_Accuracy at iter :  21  is  0.26248864668483196 . Time taken :  3.0163187980651855\n",
      "Train_loss at iter :  22  is  0.000375068477923504 . Time taken :  10.607495307922363\n",
      "Test_Accuracy at iter :  22  is  0.26248864668483196 . Time taken :  3.1000521183013916\n",
      "Train_loss at iter :  23  is  0.00016679617572812997 . Time taken :  10.161245584487915\n",
      "Test_Accuracy at iter :  23  is  0.26248864668483196 . Time taken :  3.1702866554260254\n",
      "Train_loss at iter :  24  is  0.0005216219005513281 . Time taken :  10.355759620666504\n",
      "Test_Accuracy at iter :  24  is  0.26248864668483196 . Time taken :  3.1165883541107178\n",
      "Train_loss at iter :  25  is  0.00048745119393095096 . Time taken :  10.04869532585144\n",
      "Test_Accuracy at iter :  25  is  0.26248864668483196 . Time taken :  3.3223695755004883\n",
      "Train_loss at iter :  26  is  0.000527694932976912 . Time taken :  10.296371698379517\n",
      "Test_Accuracy at iter :  26  is  0.26248864668483196 . Time taken :  2.95224928855896\n",
      "Train_loss at iter :  27  is  0.0003727820147289319 . Time taken :  10.506825923919678\n",
      "Test_Accuracy at iter :  27  is  0.26248864668483196 . Time taken :  3.1129403114318848\n",
      "Train_loss at iter :  28  is  0.0001397631253196059 . Time taken :  10.380271434783936\n",
      "Test_Accuracy at iter :  28  is  0.26248864668483196 . Time taken :  3.058109760284424\n",
      "Train_loss at iter :  29  is  0.0005104154459992598 . Time taken :  10.227430820465088\n",
      "Test_Accuracy at iter :  29  is  0.26248864668483196 . Time taken :  3.1224658489227295\n",
      "Train_loss at iter :  30  is  0.0005091426524330168 . Time taken :  10.26528549194336\n",
      "Test_Accuracy at iter :  30  is  0.26248864668483196 . Time taken :  3.207533121109009\n",
      "Train_loss at iter :  31  is  0.0005018353908695978 . Time taken :  10.573074340820312\n",
      "Test_Accuracy at iter :  31  is  0.26248864668483196 . Time taken :  3.031230926513672\n",
      "Train_loss at iter :  32  is  0.000887431176414204 . Time taken :  10.324058771133423\n",
      "Test_Accuracy at iter :  32  is  0.26248864668483196 . Time taken :  3.2218692302703857\n",
      "Train_loss at iter :  33  is  0.0003414988127094083 . Time taken :  10.416997909545898\n",
      "Test_Accuracy at iter :  33  is  0.26248864668483196 . Time taken :  3.167027235031128\n",
      "Train_loss at iter :  34  is  0.0005007190874006865 . Time taken :  10.284186840057373\n",
      "Test_Accuracy at iter :  34  is  0.26248864668483196 . Time taken :  3.1351799964904785\n",
      "Train_loss at iter :  35  is  0.0003664259160502573 . Time taken :  10.406404972076416\n",
      "Test_Accuracy at iter :  35  is  0.26248864668483196 . Time taken :  3.291325330734253\n",
      "Train_loss at iter :  36  is  0.0004896843031551062 . Time taken :  10.321781635284424\n",
      "Test_Accuracy at iter :  36  is  0.26248864668483196 . Time taken :  3.142273187637329\n",
      "Train_loss at iter :  37  is  0.0004833727405312356 . Time taken :  10.194646120071411\n",
      "Test_Accuracy at iter :  37  is  0.26248864668483196 . Time taken :  3.1625564098358154\n",
      "Train_loss at iter :  38  is  0.0004780029647805718 . Time taken :  10.137324810028076\n",
      "Test_Accuracy at iter :  38  is  0.26248864668483196 . Time taken :  3.1517019271850586\n",
      "Train_loss at iter :  39  is  0.00048050440652540116 . Time taken :  10.352916240692139\n",
      "Test_Accuracy at iter :  39  is  0.26248864668483196 . Time taken :  3.1285593509674072\n",
      "Train_loss at iter :  40  is  0.000461060232883982 . Time taken :  10.458970308303833\n",
      "Test_Accuracy at iter :  40  is  0.26248864668483196 . Time taken :  3.1811320781707764\n",
      "Train_loss at iter :  41  is  0.0005200065477064039 . Time taken :  10.467103958129883\n",
      "Test_Accuracy at iter :  41  is  0.26248864668483196 . Time taken :  3.157543420791626\n",
      "Train_loss at iter :  42  is  0.00016635225227709565 . Time taken :  10.1884024143219\n",
      "Test_Accuracy at iter :  42  is  0.26248864668483196 . Time taken :  3.126568078994751\n",
      "Train_loss at iter :  43  is  0.0009014603685350453 . Time taken :  10.353753089904785\n",
      "Test_Accuracy at iter :  43  is  0.26248864668483196 . Time taken :  3.1798593997955322\n",
      "Train_loss at iter :  44  is  0.00044109223040748625 . Time taken :  10.318509817123413\n",
      "Test_Accuracy at iter :  44  is  0.26248864668483196 . Time taken :  3.22806453704834\n",
      "Train_loss at iter :  45  is  0.00016661609212557474 . Time taken :  10.361682891845703\n",
      "Test_Accuracy at iter :  45  is  0.26248864668483196 . Time taken :  3.2568624019622803\n",
      "Train_loss at iter :  46  is  0.00017622865262102992 . Time taken :  9.844671249389648\n",
      "Test_Accuracy at iter :  46  is  0.26248864668483196 . Time taken :  3.011303663253784\n",
      "Train_loss at iter :  47  is  0.0009022367357761226 . Time taken :  9.853073358535767\n",
      "Test_Accuracy at iter :  47  is  0.26248864668483196 . Time taken :  3.0440707206726074\n",
      "Train_loss at iter :  48  is  0.0008956627564483815 . Time taken :  9.759442806243896\n",
      "Test_Accuracy at iter :  48  is  0.26248864668483196 . Time taken :  3.034236431121826\n",
      "Train_loss at iter :  49  is  0.00016524931520558474 . Time taken :  9.937708377838135\n",
      "Test_Accuracy at iter :  49  is  0.26248864668483196 . Time taken :  3.038464307785034\n",
      "Train_loss at iter :  50  is  0.00041199935955947705 . Time taken :  9.80185842514038\n",
      "Test_Accuracy at iter :  50  is  0.26248864668483196 . Time taken :  2.934619188308716\n",
      "Train_loss at iter :  51  is  0.0004335034652595663 . Time taken :  9.855651140213013\n",
      "Test_Accuracy at iter :  51  is  0.26248864668483196 . Time taken :  3.4337334632873535\n",
      "Train_loss at iter :  52  is  0.0003708109873510925 . Time taken :  9.92543625831604\n",
      "Test_Accuracy at iter :  52  is  0.26248864668483196 . Time taken :  3.029088020324707\n",
      "Train_loss at iter :  53  is  0.0001576655868733867 . Time taken :  9.934865236282349\n",
      "Test_Accuracy at iter :  53  is  0.26248864668483196 . Time taken :  3.0551183223724365\n",
      "Train_loss at iter :  54  is  0.0003965262895666258 . Time taken :  10.018056154251099\n",
      "Test_Accuracy at iter :  54  is  0.26248864668483196 . Time taken :  2.995448589324951\n",
      "Train_loss at iter :  55  is  0.00039609563484620513 . Time taken :  9.84580397605896\n",
      "Test_Accuracy at iter :  55  is  0.26248864668483196 . Time taken :  3.0487945079803467\n",
      "Train_loss at iter :  56  is  0.0003913691483633349 . Time taken :  9.821481466293335\n",
      "Test_Accuracy at iter :  56  is  0.26248864668483196 . Time taken :  3.039496660232544\n",
      "Train_loss at iter :  57  is  0.0005414642198255446 . Time taken :  9.880427360534668\n",
      "Test_Accuracy at iter :  57  is  0.26248864668483196 . Time taken :  3.008089542388916\n",
      "Train_loss at iter :  58  is  0.0008952942457091942 . Time taken :  9.868184328079224\n",
      "Test_Accuracy at iter :  58  is  0.26248864668483196 . Time taken :  3.135868549346924\n",
      "Train_loss at iter :  59  is  0.00036746827180912433 . Time taken :  9.984209537506104\n",
      "Test_Accuracy at iter :  59  is  0.26248864668483196 . Time taken :  3.0682473182678223\n",
      "Train_loss at iter :  60  is  0.00016004172213068615 . Time taken :  9.882521152496338\n",
      "Test_Accuracy at iter :  60  is  0.26248864668483196 . Time taken :  3.0963504314422607\n",
      "Train_loss at iter :  61  is  0.00056691077094846 . Time taken :  9.92395806312561\n",
      "Test_Accuracy at iter :  61  is  0.26248864668483196 . Time taken :  3.096937417984009\n",
      "Train_loss at iter :  62  is  0.00015193812744447802 . Time taken :  9.822535753250122\n",
      "Test_Accuracy at iter :  62  is  0.26248864668483196 . Time taken :  2.9997780323028564\n",
      "Train_loss at iter :  63  is  0.0005821232380491964 . Time taken :  9.973217487335205\n",
      "Test_Accuracy at iter :  63  is  0.26248864668483196 . Time taken :  3.0324974060058594\n",
      "Train_loss at iter :  64  is  0.00033158186669653275 . Time taken :  9.871389389038086\n",
      "Test_Accuracy at iter :  64  is  0.26248864668483196 . Time taken :  2.9958231449127197\n",
      "Train_loss at iter :  65  is  0.0005854467550913492 . Time taken :  9.910874605178833\n",
      "Test_Accuracy at iter :  65  is  0.26248864668483196 . Time taken :  3.010852575302124\n",
      "Train_loss at iter :  66  is  0.0004065791319372056 . Time taken :  9.81475019454956\n",
      "Test_Accuracy at iter :  66  is  0.26248864668483196 . Time taken :  3.040825605392456\n",
      "Train_loss at iter :  67  is  0.00040740879733910723 . Time taken :  10.084502696990967\n",
      "Test_Accuracy at iter :  67  is  0.26248864668483196 . Time taken :  3.013333320617676\n",
      "Train_loss at iter :  68  is  0.00033903671672728177 . Time taken :  9.963200092315674\n",
      "Test_Accuracy at iter :  68  is  0.26248864668483196 . Time taken :  3.023758888244629\n",
      "Train_loss at iter :  69  is  0.0004423573222499662 . Time taken :  10.033041954040527\n",
      "Test_Accuracy at iter :  69  is  0.26248864668483196 . Time taken :  3.7108712196350098\n",
      "Train_loss at iter :  70  is  0.00014898748824212436 . Time taken :  12.35742974281311\n",
      "Test_Accuracy at iter :  70  is  0.26248864668483196 . Time taken :  3.6741209030151367\n",
      "Train_loss at iter :  71  is  0.00015965438960643296 . Time taken :  10.601470708847046\n",
      "Test_Accuracy at iter :  71  is  0.26248864668483196 . Time taken :  3.1844799518585205\n",
      "Train_loss at iter :  72  is  0.00030837604280714684 . Time taken :  10.34932565689087\n",
      "Test_Accuracy at iter :  72  is  0.26248864668483196 . Time taken :  3.19982647895813\n",
      "Train_loss at iter :  73  is  0.000906425134073036 . Time taken :  10.184881687164307\n",
      "Test_Accuracy at iter :  73  is  0.26248864668483196 . Time taken :  3.191805362701416\n",
      "Train_loss at iter :  74  is  0.00013946116751945866 . Time taken :  10.312343120574951\n",
      "Test_Accuracy at iter :  74  is  0.26248864668483196 . Time taken :  3.1613242626190186\n",
      "Train_loss at iter :  75  is  0.0003280826052476404 . Time taken :  10.149473190307617\n",
      "Test_Accuracy at iter :  75  is  0.26248864668483196 . Time taken :  3.1509010791778564\n",
      "Train_loss at iter :  76  is  0.0005773644657170728 . Time taken :  10.16819143295288\n",
      "Test_Accuracy at iter :  76  is  0.26248864668483196 . Time taken :  3.2939088344573975\n",
      "Train_loss at iter :  77  is  0.0005958627225754413 . Time taken :  10.151562452316284\n",
      "Test_Accuracy at iter :  77  is  0.26248864668483196 . Time taken :  3.129276990890503\n",
      "Train_loss at iter :  78  is  0.0005781959728355265 . Time taken :  10.152272462844849\n",
      "Test_Accuracy at iter :  78  is  0.26248864668483196 . Time taken :  3.151038408279419\n",
      "Train_loss at iter :  79  is  0.0009066557393091895 . Time taken :  10.197836637496948\n",
      "Test_Accuracy at iter :  79  is  0.26248864668483196 . Time taken :  3.160128593444824\n",
      "Train_loss at iter :  80  is  0.0005637353725647658 . Time taken :  10.229955434799194\n",
      "Test_Accuracy at iter :  80  is  0.26248864668483196 . Time taken :  3.1660192012786865\n",
      "Train_loss at iter :  81  is  0.0001477367394649134 . Time taken :  10.449599266052246\n",
      "Test_Accuracy at iter :  81  is  0.26248864668483196 . Time taken :  3.141878128051758\n",
      "Train_loss at iter :  82  is  0.0002719879373628995 . Time taken :  10.18590259552002\n",
      "Test_Accuracy at iter :  82  is  0.26248864668483196 . Time taken :  3.1476330757141113\n",
      "Train_loss at iter :  83  is  0.0009018598535980624 . Time taken :  10.295915603637695\n",
      "Test_Accuracy at iter :  83  is  0.26248864668483196 . Time taken :  3.4895665645599365\n",
      "Train_loss at iter :  84  is  0.00014590731497560994 . Time taken :  10.215030193328857\n",
      "Test_Accuracy at iter :  84  is  0.26248864668483196 . Time taken :  3.153327465057373\n",
      "Train_loss at iter :  85  is  0.0008857074413406715 . Time taken :  7.799583673477173\n",
      "Test_Accuracy at iter :  85  is  0.26248864668483196 . Time taken :  1.7172040939331055\n",
      "Train_loss at iter :  86  is  0.00012914539220627773 . Time taken :  5.283764123916626\n",
      "Test_Accuracy at iter :  86  is  0.26248864668483196 . Time taken :  1.3770256042480469\n",
      "Train_loss at iter :  87  is  0.0005526547128341618 . Time taken :  4.444473028182983\n",
      "Test_Accuracy at iter :  87  is  0.26248864668483196 . Time taken :  1.3757476806640625\n",
      "Train_loss at iter :  88  is  0.0003235116042894371 . Time taken :  4.332605600357056\n",
      "Test_Accuracy at iter :  88  is  0.26248864668483196 . Time taken :  1.3447909355163574\n",
      "Train_loss at iter :  89  is  0.00025479146715407067 . Time taken :  4.314739942550659\n",
      "Test_Accuracy at iter :  89  is  0.26248864668483196 . Time taken :  1.3479654788970947\n",
      "Train_loss at iter :  90  is  0.0002510519175047285 . Time taken :  4.283735752105713\n",
      "Test_Accuracy at iter :  90  is  0.26248864668483196 . Time taken :  1.3301925659179688\n",
      "Train_loss at iter :  91  is  0.0002754256687360756 . Time taken :  4.252038478851318\n",
      "Test_Accuracy at iter :  91  is  0.26248864668483196 . Time taken :  1.3463354110717773\n",
      "Train_loss at iter :  92  is  0.00018375810612453503 . Time taken :  4.248109817504883\n",
      "Test_Accuracy at iter :  92  is  0.26248864668483196 . Time taken :  1.3434388637542725\n",
      "Train_loss at iter :  93  is  0.0008779941649919146 . Time taken :  4.316375970840454\n",
      "Test_Accuracy at iter :  93  is  0.26248864668483196 . Time taken :  1.3451974391937256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss at iter :  94  is  0.0005643919166107749 . Time taken :  4.851523160934448\n",
      "Test_Accuracy at iter :  94  is  0.26067211625794734 . Time taken :  1.4219129085540771\n",
      "Train_loss at iter :  95  is  0.0001289344738038738 . Time taken :  4.968792200088501\n",
      "Test_Accuracy at iter :  95  is  0.2633969118982743 . Time taken :  1.4530854225158691\n",
      "Train_loss at iter :  96  is  0.0006505682897031977 . Time taken :  4.734372615814209\n",
      "Test_Accuracy at iter :  96  is  0.2652134423251589 . Time taken :  1.3437483310699463\n",
      "Train_loss at iter :  97  is  0.00018254042453087223 . Time taken :  4.734376907348633\n",
      "Test_Accuracy at iter :  97  is  0.2615803814713896 . Time taken :  1.3906264305114746\n",
      "Train_loss at iter :  98  is  0.0007279327188091778 . Time taken :  4.515620470046997\n",
      "Test_Accuracy at iter :  98  is  0.2724795640326976 . Time taken :  1.3906290531158447\n",
      "Train_loss at iter :  99  is  0.00014138481255327717 . Time taken :  4.578124761581421\n",
      "Test_Accuracy at iter :  99  is  0.2724795640326976 . Time taken :  1.4062469005584717\n"
     ]
    }
   ],
   "source": [
    "builder = TreeLSTMBuilder(model, w2i, HID_SIZE, EMB_SIZE)\n",
    "\n",
    "# lets perform Training\n",
    "print('Started Training .....')\n",
    "\n",
    "for i in range(100):\n",
    "    # randomly shuffle the training examples\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    trainLoss = 0\n",
    "    startTime = time.time()\n",
    "    for tree in train:\n",
    "        myLoss = dy.hinge(computeScores(tree), l2i[tree.label]) # can pick neg logsoftmaxloss also\n",
    "        \n",
    "    trainLoss += myLoss.value()\n",
    "    myLoss.backward()\n",
    "    trainer.update()\n",
    "    print(\"Train_loss at iter : \",i,\" is \",trainLoss/len(train),'. Time taken : ',(-startTime+time.time()))\n",
    "    \n",
    "    startTime = time.time()\n",
    "    correct = 0\n",
    "    for tree in dev:\n",
    "        scores = computeScores(tree).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        if(predict==l2i[tree.label]):\n",
    "            correct += 1\n",
    "    print(\"Test_Accuracy at iter : \",i,\" is \",correct/len(dev),'. Time taken : ',(-startTime+time.time()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
