{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------------------------\n",
    "## Summary : Implementing the Conv neural nets for sentence classification\n",
    "## Author  : Srinivas Venkata Vemparala\n",
    "## Source  : https://github.com/neubig/nn4nlp-code\n",
    "##---------------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dynet as dy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# lets convert the words into integer\n",
    "# The default dictionary takes a function as input and outupts \n",
    "# it if key is not present in the map.\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "\n",
    "# create an unknown token. As this is the first it will be 0\n",
    "UNK =w2i['<unk>']\n",
    "print(UNK)\n",
    "\n",
    "# Lets write a method to read the data.\n",
    "# This method returns the list of [features, label].\n",
    "# Here the features are integer ids of words and tags are labels\n",
    "def readDataSet(fileName):\n",
    "    retList = []\n",
    "    with open(fileName,'r+') as f:\n",
    "        for line in f:\n",
    "            tag,words = line.lower().strip().split(' ||| ')\n",
    "            \n",
    "            # now get the features which is the integerIds of words\n",
    "            features = [w2i[x] for x in words.split(' ')]\n",
    "            label = t2i[tag]\n",
    "            \n",
    "            # add the data to the list\n",
    "            retList.append([features,label])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18648 : 5\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "train = readDataSet('../data/classes/train.txt')\n",
    "test = readDataSet(\"../data/classes/test.txt\")\n",
    "nWords = len(w2i)\n",
    "nTags = len(t2i)\n",
    "\n",
    "# lets freeze the dictionary\n",
    "w2i = defaultdict(lambda:UNK, len(w2i))\n",
    "\n",
    "print(nWords,':',nTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets define an embedding size and a filter size\n",
    "nEmb = 128            # length of the embedding vector for each word\n",
    "nFilter = 128         # number of filters\n",
    "winSize = 3          # this is similar to N in N-grams.\n",
    "\n",
    "\n",
    "# lets declare the model and the trainer.\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)\n",
    "\n",
    "\n",
    "# lets declare the parameters which will be added to the model\n",
    "W_emb = model.add_lookup_parameters((nWords,1,1,nEmb))   # the features are on z-axis :)\n",
    "\n",
    "W_cnn = model.add_parameters((1,winSize,nEmb,nFilter))   # the weights of CNN layer\n",
    "b_cnn = model.add_parameters((nFilter))                  # biases of the CNN layer\n",
    "\n",
    "W_sm = model.add_parameters((nTags,nFilter))             # weights of softmax layer\n",
    "b_sm = model.add_parameters((nTags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets write a method to compute the scores given a sentence\n",
    "def computeScores(sent):\n",
    "    # renew the computation graph\n",
    "    dy.renew_cg()\n",
    "    \n",
    "    # get the parameters to computation graph\n",
    "    weightsCNN = dy.parameter(W_cnn)\n",
    "    biasesCNN = dy.parameter(b_cnn)\n",
    "    weightsSM = dy.parameter(W_sm)\n",
    "    biasesSM = dy.parameter(b_sm)\n",
    "    \n",
    "    # if the sent is smaller than the window size then we will have problems\n",
    "    # if that is case add enough UNK\n",
    "    if len(sent) < winSize:\n",
    "        sent += [0] * (winSize-len(sent))\n",
    "\n",
    "    embed = [W_emb[x] for x in sent]\n",
    "    cnnInput = dy.concatenate(embed,d=1) # concatenate the embeddings in column dimension\n",
    "    cnnOutput = dy.conv2d_bias(cnnInput,weightsCNN,biasesCNN,is_valid=False,stride=(1,1))\n",
    "    \n",
    "    # do max pooling\n",
    "    poolOut = dy.max_dim(cnnOutput,d=1)               # get the output of pooling\n",
    "    poolOut = dy.reshape(poolOut, (nFilter,))   # reshape it to get the filter size\n",
    "    \n",
    "    # apply relu function\n",
    "    poolOut = dy.rectify(poolOut)\n",
    "    \n",
    "    return (weightsSM*poolOut+biasesSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration  0  the training accuracy is :  0.31624531835205993  time taken :  88.07636022567749\n",
      "At iteration  0  the test accuracy is :  0.35339366515837106  time taken :  92.71276187896729\n",
      "At iteration  1  the training accuracy is :  0.5724485018726592  time taken :  88.24254965782166\n",
      "At iteration  1  the test accuracy is :  0.38416289592760183  time taken :  92.86141872406006\n",
      "At iteration  2  the training accuracy is :  0.8328651685393258  time taken :  88.43943214416504\n",
      "At iteration  2  the test accuracy is :  0.3588235294117647  time taken :  93.04235649108887\n",
      "At iteration  3  the training accuracy is :  0.9735486891385767  time taken :  91.87499523162842\n",
      "At iteration  3  the test accuracy is :  0.3606334841628959  time taken :  97.42922854423523\n",
      "At iteration  4  the training accuracy is :  0.995435393258427  time taken :  88.2517557144165\n",
      "At iteration  4  the test accuracy is :  0.3547511312217195  time taken :  92.87037229537964\n",
      "At iteration  5  the training accuracy is :  0.9996488764044944  time taken :  88.1777868270874\n",
      "At iteration  5  the test accuracy is :  0.3556561085972851  time taken :  92.81853652000427\n",
      "At iteration  6  the training accuracy is :  0.9997659176029963  time taken :  88.80821585655212\n",
      "At iteration  6  the test accuracy is :  0.3552036199095023  time taken :  93.43932104110718\n",
      "At iteration  7  the training accuracy is :  0.9997659176029963  time taken :  88.4098949432373\n",
      "At iteration  7  the test accuracy is :  0.3583710407239819  time taken :  93.07571458816528\n",
      "At iteration  8  the training accuracy is :  0.9998829588014981  time taken :  88.22664189338684\n",
      "At iteration  8  the test accuracy is :  0.3579185520361991  time taken :  92.86720442771912\n",
      "At iteration  9  the training accuracy is :  1.0  time taken :  88.11895203590393\n",
      "At iteration  9  the test accuracy is :  0.36153846153846153  time taken :  92.71268033981323\n",
      "At iteration  10  the training accuracy is :  1.0  time taken :  88.54170870780945\n",
      "At iteration  10  the test accuracy is :  0.3565610859728507  time taken :  93.13540029525757\n",
      "At iteration  11  the training accuracy is :  1.0  time taken :  87.45201635360718\n",
      "At iteration  11  the test accuracy is :  0.3547511312217195  time taken :  92.04571151733398\n",
      "At iteration  12  the training accuracy is :  1.0  time taken :  87.54525375366211\n",
      "At iteration  12  the test accuracy is :  0.3561085972850679  time taken :  92.13889813423157\n",
      "At iteration  13  the training accuracy is :  1.0  time taken :  88.86692547798157\n",
      "At iteration  13  the test accuracy is :  0.35429864253393667  time taken :  93.52744889259338\n",
      "At iteration  14  the training accuracy is :  1.0  time taken :  89.49078345298767\n",
      "At iteration  14  the test accuracy is :  0.3561085972850679  time taken :  94.10007095336914\n",
      "At iteration  15  the training accuracy is :  1.0  time taken :  87.70150184631348\n",
      "At iteration  15  the test accuracy is :  0.3561085972850679  time taken :  92.2639434337616\n",
      "At iteration  16  the training accuracy is :  1.0  time taken :  87.53014421463013\n",
      "At iteration  16  the test accuracy is :  0.3561085972850679  time taken :  92.23320245742798\n",
      "At iteration  17  the training accuracy is :  1.0  time taken :  87.80133056640625\n",
      "At iteration  17  the test accuracy is :  0.3556561085972851  time taken :  92.48859333992004\n",
      "At iteration  18  the training accuracy is :  1.0  time taken :  88.11525321006775\n",
      "At iteration  18  the test accuracy is :  0.35429864253393667  time taken :  92.69316124916077\n",
      "At iteration  19  the training accuracy is :  1.0  time taken :  87.92657232284546\n",
      "At iteration  19  the test accuracy is :  0.3552036199095023  time taken :  92.79147601127625\n",
      "At iteration  20  the training accuracy is :  1.0  time taken :  87.41868567466736\n",
      "At iteration  20  the test accuracy is :  0.3547511312217195  time taken :  92.04357933998108\n",
      "At iteration  21  the training accuracy is :  1.0  time taken :  87.59097719192505\n",
      "At iteration  21  the test accuracy is :  0.3547511312217195  time taken :  92.168954372406\n",
      "At iteration  22  the training accuracy is :  1.0  time taken :  87.46596765518188\n",
      "At iteration  22  the test accuracy is :  0.3552036199095023  time taken :  92.02832508087158\n",
      "At iteration  23  the training accuracy is :  1.0  time taken :  87.28485441207886\n",
      "At iteration  23  the test accuracy is :  0.3552036199095023  time taken :  91.86283588409424\n",
      "At iteration  24  the training accuracy is :  1.0  time taken :  92.13540625572205\n",
      "At iteration  24  the test accuracy is :  0.3547511312217195  time taken :  97.65663766860962\n"
     ]
    }
   ],
   "source": [
    "# Now lets perform the the training\n",
    "bestTestAccuracy = 0\n",
    "lastTestAccuracy = 0\n",
    "\n",
    "for i in range(25):\n",
    "    # Perform the shuffling of the training data\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    # initialize the training loss and time\n",
    "    startTime = time.time()\n",
    "    trainLoss = 0\n",
    "    trainCorrect = 0\n",
    "    \n",
    "    # train\n",
    "    for words,tag in train:\n",
    "        scores = computeScores(words)\n",
    "        predict = np.argmax(scores.npvalue())\n",
    "        if(predict==tag):\n",
    "            trainCorrect = trainCorrect+1\n",
    "        \n",
    "        loss = dy.pickneglogsoftmax(scores,tag)\n",
    "        trainLoss += loss.value()\n",
    "        \n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print('At iteration ',i,' the training accuracy is : ',(trainCorrect/len(train)),' time taken : ',(time.time()-startTime))\n",
    "    \n",
    "    testLoss = 0\n",
    "    testCorrect = 0\n",
    "    # test\n",
    "    for words,tag in test:\n",
    "        scores = computeScores(words)\n",
    "        predict = np.argmax(scores.npvalue())\n",
    "        if(predict==tag):\n",
    "            testCorrect += 1\n",
    "    testAccuracy = testCorrect/len(test)\n",
    "    if(testAccuracy>bestTestAccuracy):\n",
    "        bestTestAccuracy = testAccuracy\n",
    "    \n",
    "    if(testAccuracy<lastTestAccuracy):\n",
    "        trainer.learning_rate = trainer.learning_rate/2\n",
    "    lastTestAccuracy = testAccuracy\n",
    "    \n",
    "    print('At iteration ',i,' the test accuracy is : ',(testAccuracy),' time taken : ',(time.time()-startTime))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
