{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------------------------\n",
    "## Summary : Implementing simple LSTM for sentiment classification\n",
    "## Author  : Srinivas Venkata Vemparala\n",
    "## Source  : https://github.com/neubig/nn4nlp-code\n",
    "##---------------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dynet as dy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets convert the words into integer\n",
    "# The default dictionary takes a function as input and outupts \n",
    "# it if key is not present in the map.\n",
    "w2i = defaultdict(lambda : len(w2i))\n",
    "t2i = defaultdict(lambda : len(t2i))\n",
    "\n",
    "# create an unknown token. As this is the first it will be 0\n",
    "UNK =w2i['<unk>']\n",
    "\n",
    "# Lets write a method to read the data.\n",
    "# This method returns the list of [features, label].\n",
    "# Here the features are integer ids of words and tags are labels\n",
    "def readDataSet(fileName):\n",
    "    retList = []\n",
    "    with open(fileName,'r+') as f:\n",
    "        for line in f:\n",
    "            tag,sentence = line.lower().strip().split(' ||| ') \n",
    "            words = sentence.lower().strip().split(' ')\n",
    "            features = [w2i[x] for x in words]\n",
    "            label = t2i[tag]\n",
    "            \n",
    "            retList.append([features,label])\n",
    "            \n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18648  :  5\n"
     ]
    }
   ],
   "source": [
    "train = readDataSet('../data/classes/train.txt')\n",
    "test = readDataSet('../data/classes/test.txt')\n",
    "nWords = len(w2i)\n",
    "ntags = len(t2i)\n",
    "\n",
    "# lets freeze the dictionary\n",
    "w2i = defaultdict(lambda:UNK, len(w2i))\n",
    "\n",
    "print(nWords,' : ',ntags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets define the embedding size and hidden size\n",
    "nEmb = 64\n",
    "nHid = 64\n",
    "\n",
    "# lets define the model and the trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)\n",
    "\n",
    "# lets add the parameters to the model\n",
    "W_emb = model.add_lookup_parameters((nWords,nEmb))\n",
    "\n",
    "# lets define two LSTM rnns one for forward and other for backward\n",
    "forwardRNN = dy.VanillaLSTMBuilder(1,nEmb,nHid,model)\n",
    "backWardRNN = dy.VanillaLSTMBuilder(1,nEmb,nHid,model)\n",
    "\n",
    "# lets declare the softmax weights\n",
    "W_sm = model.add_parameters((ntags,2*nHid))\n",
    "b_sm = model.add_parameters((ntags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeScores(words):\n",
    "    # renew the computation graph\n",
    "    dy.renew_cg()\n",
    "    \n",
    "    # get the embeddings\n",
    "    embeddings = [W_emb[x] for x in words]\n",
    "    \n",
    "    # get the init state for the rnns\n",
    "    finit = forwardRNN.initial_state()\n",
    "    binit = backWardRNN.initial_state()\n",
    "    \n",
    "    # lets pass the inputs through rnns one from the start and other from back\n",
    "    fwdembs = finit.transduce(embeddings)\n",
    "    embeddings.reverse()                  # reverse the word embeddings\n",
    "    bwdembs = binit.transduce(embeddings)\n",
    "    \n",
    "    # get the last word in two embeddings and concatenate them together\n",
    "    finalEmb = dy.concatenate([fwdembs[-1],bwdembs[-1]])\n",
    "    \n",
    "    # get the weights and biases of the softmax layer. \n",
    "    weightsSoftmax = dy.parameter(W_sm)\n",
    "    biasesSoftmax = dy.parameter(b_sm)\n",
    "    \n",
    "    return (weightsSoftmax*finalEmb + biasesSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration  0  the training accuracy is :  0.3240870786516854  time taken :  55.45553994178772\n",
      "At iteration  0  the test accuracy is :  0.38054298642533935  time taken :  59.80601453781128\n",
      "At iteration  1  the training accuracy is :  0.475187265917603  time taken :  63.124500036239624\n",
      "At iteration  1  the test accuracy is :  0.3832579185520362  time taken :  67.66438913345337\n",
      "At iteration  2  the training accuracy is :  0.6036985018726592  time taken :  53.11413335800171\n",
      "At iteration  2  the test accuracy is :  0.39819004524886875  time taken :  57.68433690071106\n",
      "At iteration  3  the training accuracy is :  0.7442649812734082  time taken :  52.96915912628174\n",
      "At iteration  3  the test accuracy is :  0.40226244343891404  time taken :  57.3459734916687\n",
      "At iteration  4  the training accuracy is :  0.8576779026217228  time taken :  52.303807973861694\n",
      "At iteration  4  the test accuracy is :  0.3909502262443439  time taken :  56.719923973083496\n",
      "At iteration  5  the training accuracy is :  0.9408941947565543  time taken :  52.44011974334717\n",
      "At iteration  5  the test accuracy is :  0.39683257918552034  time taken :  56.85925793647766\n",
      "At iteration  6  the training accuracy is :  0.9712078651685393  time taken :  51.60658550262451\n",
      "At iteration  6  the test accuracy is :  0.38416289592760183  time taken :  55.994978189468384\n",
      "At iteration  7  the training accuracy is :  0.9889981273408239  time taken :  50.126912355422974\n",
      "At iteration  7  the test accuracy is :  0.3990950226244344  time taken :  54.44720101356506\n",
      "At iteration  8  the training accuracy is :  0.9943820224719101  time taken :  52.19498682022095\n",
      "At iteration  8  the test accuracy is :  0.38597285067873305  time taken :  56.45303797721863\n",
      "At iteration  9  the training accuracy is :  0.9978932584269663  time taken :  50.93476843833923\n",
      "At iteration  9  the test accuracy is :  0.3950226244343891  time taken :  55.18064546585083\n",
      "At iteration  10  the training accuracy is :  0.9987125468164794  time taken :  49.88793468475342\n",
      "At iteration  10  the test accuracy is :  0.3891402714932127  time taken :  54.10114765167236\n",
      "At iteration  11  the training accuracy is :  0.9992977528089888  time taken :  50.17066788673401\n",
      "At iteration  11  the test accuracy is :  0.3832579185520362  time taken :  54.421640396118164\n",
      "At iteration  12  the training accuracy is :  0.9997659176029963  time taken :  50.12170886993408\n",
      "At iteration  12  the test accuracy is :  0.3914027149321267  time taken :  54.39516854286194\n",
      "At iteration  13  the training accuracy is :  0.9998829588014981  time taken :  49.9993212223053\n",
      "At iteration  13  the test accuracy is :  0.38823529411764707  time taken :  54.23586082458496\n",
      "At iteration  14  the training accuracy is :  0.9998829588014981  time taken :  50.130839109420776\n",
      "At iteration  14  the test accuracy is :  0.38823529411764707  time taken :  54.37198042869568\n",
      "At iteration  15  the training accuracy is :  0.9998829588014981  time taken :  49.96359062194824\n",
      "At iteration  15  the test accuracy is :  0.3900452488687783  time taken :  54.18815493583679\n",
      "At iteration  16  the training accuracy is :  0.9998829588014981  time taken :  50.054672956466675\n",
      "At iteration  16  the test accuracy is :  0.38733031674208146  time taken :  54.271730184555054\n",
      "At iteration  17  the training accuracy is :  0.9998829588014981  time taken :  50.07902979850769\n",
      "At iteration  17  the test accuracy is :  0.38823529411764707  time taken :  54.33569359779358\n",
      "At iteration  18  the training accuracy is :  0.9998829588014981  time taken :  49.91422891616821\n",
      "At iteration  18  the test accuracy is :  0.38733031674208146  time taken :  54.137964487075806\n",
      "At iteration  19  the training accuracy is :  0.9998829588014981  time taken :  50.22157692909241\n",
      "At iteration  19  the test accuracy is :  0.38687782805429866  time taken :  54.45554184913635\n",
      "At iteration  20  the training accuracy is :  0.9998829588014981  time taken :  50.440274477005005\n",
      "At iteration  20  the test accuracy is :  0.38687782805429866  time taken :  54.694010734558105\n",
      "At iteration  21  the training accuracy is :  0.9998829588014981  time taken :  49.942681312561035\n",
      "At iteration  21  the test accuracy is :  0.38687782805429866  time taken :  54.16668462753296\n",
      "At iteration  22  the training accuracy is :  0.9998829588014981  time taken :  50.01927185058594\n",
      "At iteration  22  the test accuracy is :  0.38642533936651585  time taken :  54.22777581214905\n",
      "At iteration  23  the training accuracy is :  0.9998829588014981  time taken :  49.968987226486206\n",
      "At iteration  23  the test accuracy is :  0.38642533936651585  time taken :  54.193177223205566\n",
      "At iteration  24  the training accuracy is :  0.9998829588014981  time taken :  49.97120523452759\n",
      "At iteration  24  the test accuracy is :  0.38642533936651585  time taken :  54.236825942993164\n"
     ]
    }
   ],
   "source": [
    "# Now lets perform the the training\n",
    "bestTestAccuracy = 0\n",
    "lastTestAccuracy = 0\n",
    "\n",
    "for i in range(25):\n",
    "    # Perform the shuffling of the training data\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    # initialize the training loss and time\n",
    "    startTime = time.time()\n",
    "    trainLoss = 0\n",
    "    trainCorrect = 0\n",
    "    \n",
    "    # train\n",
    "    for words,tag in train:\n",
    "        scores = computeScores(words)\n",
    "        predict = np.argmax(scores.npvalue())\n",
    "        if(predict==tag):\n",
    "            trainCorrect = trainCorrect+1\n",
    "        \n",
    "        loss = dy.pickneglogsoftmax(scores,tag)\n",
    "        trainLoss += loss.value()\n",
    "        \n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print('At iteration ',i,' the training accuracy is : ',(trainCorrect/len(train)),' time taken : ',(time.time()-startTime))\n",
    "    \n",
    "    testLoss = 0\n",
    "    testCorrect = 0\n",
    "    # test\n",
    "    for words,tag in test:\n",
    "        scores = computeScores(words)\n",
    "        predict = np.argmax(scores.npvalue())\n",
    "        if(predict==tag):\n",
    "            testCorrect += 1\n",
    "    testAccuracy = testCorrect/len(test)\n",
    "    if(testAccuracy>bestTestAccuracy):\n",
    "        bestTestAccuracy = testAccuracy\n",
    "    \n",
    "    if(testAccuracy<lastTestAccuracy):\n",
    "        trainer.learning_rate = trainer.learning_rate/2\n",
    "    lastTestAccuracy = testAccuracy\n",
    "    \n",
    "    print('At iteration ',i,' the test accuracy is : ',(testAccuracy),' time taken : ',(time.time()-startTime))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
