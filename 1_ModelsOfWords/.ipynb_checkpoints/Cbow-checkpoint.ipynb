{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------------\n",
    "## Summary : Implementing the Continuios Bag of Words\n",
    "## Author  : Srinivas Venkata Vemparala\n",
    "## Source  : https://github.com/neubig/nn4nlp-code\n",
    "##---------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dynet as dy\n",
    "import time\n",
    "import random\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets declare the size of the word embedding which we will use\n",
    "nEmb = 64\n",
    "\n",
    "# create the methods to convert word to integer. We will use default dict\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i['<unk>']\n",
    "\n",
    "# Now lets define the methods to read dataSet.\n",
    "# This returns a list of [features,labels]\n",
    "def readDataSet(fileName):\n",
    "    retList = []\n",
    "    \n",
    "    with open(fileName,'r+') as file:\n",
    "        for line in file:\n",
    "            tag,words = line.lower().strip().split(' ||| ')\n",
    "            \n",
    "            # Get the features from words which is list of int id for each word\n",
    "            features = [w2i[x] for x in words.split(' ')]\n",
    "            # Get the label from tag i..e convert tag to int\n",
    "            label = t2i[tag]\n",
    "            retList.append([features,label])\n",
    "            \n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18648  :  5\n",
      "train[0] : [[1, 2, 3, 4, 5, 6, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 9, 17, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 0]\n",
      "test[0] : [[1795, 71, 16582, 448], 2]\n"
     ]
    }
   ],
   "source": [
    "# read the training data and test data\n",
    "train = readDataSet(fileName='../data/classes/train.txt')\n",
    "test = readDataSet(fileName='../data/classes/test.txt')\n",
    "\n",
    "nWords = len(w2i)\n",
    "nTags = len(t2i)\n",
    "print(nWords,' : ',nTags)\n",
    "\n",
    "# lets freeze the dictionary\n",
    "w2i = defaultdict(lambda:UNK, len(w2i))\n",
    "\n",
    "print('train[0] :',train[0])\n",
    "print('test[0] :',test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets declare the model and trainers\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)\n",
    "\n",
    "# lets declare the parameters which we use\n",
    "W_emb = model.add_lookup_parameters((nWords,nEmb))\n",
    "W_sm = model.add_parameters((nTags,nEmb))\n",
    "b_sm = model.add_parameters(nTags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets define a method to compute the scores once the parameters are given\n",
    "def computeScores(words):\n",
    "    # renew the computation graph\n",
    "    dy.renew_cg()\n",
    "    \n",
    "    biases_softMax = dy.parameter(b_sm)\n",
    "    W_softMax = dy.parameter(W_sm)\n",
    "    \n",
    "    scores = dy.esum([dy.lookup(W_emb,x) for x in words])\n",
    "    scores = W_softMax*scores + biases_softMax\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration  0  the training loss is :  13449.677063882351  time taken :  1.4486079216003418\n",
      "At iteration  0  the test accuracy is :  36.96832579185521 %\n",
      "At iteration  1  the training loss is :  9663.444181382656  time taken :  1.4854578971862793\n",
      "At iteration  1  the test accuracy is :  39.90950226244344 %\n",
      "At iteration  2  the training loss is :  6556.493509411812  time taken :  1.4620018005371094\n",
      "At iteration  2  the test accuracy is :  38.68778280542987 %\n",
      "At iteration  3  the training loss is :  4243.158288538456  time taken :  1.4025015830993652\n",
      "At iteration  3  the test accuracy is :  39.366515837104075 %\n",
      "At iteration  4  the training loss is :  2770.2708449959755  time taken :  1.6375033855438232\n",
      "At iteration  4  the test accuracy is :  37.828054298642535 %\n",
      "At iteration  5  the training loss is :  1867.002669274807  time taken :  1.8270118236541748\n",
      "At iteration  5  the test accuracy is :  38.1447963800905 %\n",
      "At iteration  6  the training loss is :  1435.2784430384636  time taken :  2.054084539413452\n",
      "At iteration  6  the test accuracy is :  38.73303167420815 %\n",
      "At iteration  7  the training loss is :  1062.9939383268356  time taken :  2.1775004863739014\n",
      "At iteration  7  the test accuracy is :  36.515837104072396 %\n",
      "At iteration  8  the training loss is :  691.1287685632706  time taken :  2.3800041675567627\n",
      "At iteration  8  the test accuracy is :  37.873303167420815 %\n",
      "At iteration  9  the training loss is :  696.5835622549057  time taken :  3.0914995670318604\n",
      "At iteration  9  the test accuracy is :  37.60180995475113 %\n",
      "At iteration  10  the training loss is :  617.8510391712189  time taken :  2.927001476287842\n",
      "At iteration  10  the test accuracy is :  36.69683257918552 %\n",
      "At iteration  11  the training loss is :  491.6773864030838  time taken :  3.0849997997283936\n",
      "At iteration  11  the test accuracy is :  37.782805429864254 %\n",
      "At iteration  12  the training loss is :  513.6706149578094  time taken :  3.3938584327697754\n",
      "At iteration  12  the test accuracy is :  37.19457013574661 %\n",
      "At iteration  13  the training loss is :  567.3130979537964  time taken :  3.161545753479004\n",
      "At iteration  13  the test accuracy is :  37.19457013574661 %\n",
      "At iteration  14  the training loss is :  418.61926102638245  time taken :  3.291541814804077\n",
      "At iteration  14  the test accuracy is :  35.83710407239819 %\n",
      "At iteration  15  the training loss is :  489.14222288131714  time taken :  3.305501699447632\n",
      "At iteration  15  the test accuracy is :  35.38461538461539 %\n",
      "At iteration  16  the training loss is :  425.43881392478943  time taken :  3.4545037746429443\n",
      "At iteration  16  the test accuracy is :  36.96832579185521 %\n",
      "At iteration  17  the training loss is :  420.20044136047363  time taken :  3.420959711074829\n",
      "At iteration  17  the test accuracy is :  36.65158371040724 %\n",
      "At iteration  18  the training loss is :  323.37324142456055  time taken :  3.48429536819458\n",
      "At iteration  18  the test accuracy is :  38.05429864253394 %\n",
      "At iteration  19  the training loss is :  477.16672921180725  time taken :  3.561457633972168\n",
      "At iteration  19  the test accuracy is :  35.88235294117647 %\n",
      "At iteration  20  the training loss is :  328.2443115711212  time taken :  3.6315014362335205\n",
      "At iteration  20  the test accuracy is :  35.97285067873303 %\n",
      "At iteration  21  the training loss is :  404.27145779132843  time taken :  3.7270028591156006\n",
      "At iteration  21  the test accuracy is :  36.10859728506787 %\n",
      "At iteration  22  the training loss is :  375.33122873306274  time taken :  3.497000217437744\n",
      "At iteration  22  the test accuracy is :  37.782805429864254 %\n",
      "At iteration  23  the training loss is :  439.89210081100464  time taken :  3.6159985065460205\n",
      "At iteration  23  the test accuracy is :  35.248868778280546 %\n",
      "At iteration  24  the training loss is :  451.6520586013794  time taken :  3.6320037841796875\n",
      "At iteration  24  the test accuracy is :  36.65158371040724 %\n"
     ]
    }
   ],
   "source": [
    "# lets start training \n",
    "for i in range(25):\n",
    "    # let's shuffle the training examples\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    # initialize the training loss to zero and note time\n",
    "    startTime = time.time()\n",
    "    trainLoss = 0\n",
    "    # perform training\n",
    "    for words, tag in train:\n",
    "        loss = dy.pickneglogsoftmax(computeScores(words=words),tag)\n",
    "        trainLoss = trainLoss + loss.value()\n",
    "        \n",
    "        # compute the gradients and update the parameters\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print('At iteration ',i,' the training loss is : ',trainLoss,' time taken : ',(time.time()-startTime))\n",
    "    \n",
    "    # compute test loss\n",
    "    testCorr = 0\n",
    "    for words, tag in test:\n",
    "        scores = computeScores(words).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        \n",
    "        if(predict==tag):\n",
    "            testCorr = testCorr+1\n",
    "    print('At iteration ',i,' the test accuracy is : ',(testCorr/len(test))*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
