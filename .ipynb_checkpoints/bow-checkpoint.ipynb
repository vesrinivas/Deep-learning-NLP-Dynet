{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dynet as dy\n",
    "import time \n",
    "\n",
    "import random as random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# lets convert the words into integer\n",
    "# The default dictionary takes a function as input and outupts \n",
    "# it if key is not present in the map.\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "\n",
    "# create an unknown token. As this is the first it will be 0\n",
    "UNK =w2i['<unk>']\n",
    "print(UNK)\n",
    "\n",
    "# Lets write a method to read the data.\n",
    "# This method returns the list of [features, label].\n",
    "# Here the features are integer ids of words and tags are labels\n",
    "def readDataSet(fileName):\n",
    "    retList = []\n",
    "    with open(fileName,'r+') as f:\n",
    "        for line in f:\n",
    "            tag,words = line.lower().strip().split(' ||| ')\n",
    "            \n",
    "            # now get the features which is the integerIds of words\n",
    "            features = [w2i[x] for x in words.split(' ')]\n",
    "            label = t2i[tag]\n",
    "            \n",
    "            # add the data to the list\n",
    "            retList.append([features,label])\n",
    "    return retList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18648 : 5\n",
      "train[0] : \n",
      " [[1, 2, 3, 4, 5, 6, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 9, 17, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 0]\n",
      "test[0] : \n",
      " [[1795, 71, 0, 448], 2]\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "train = readDataSet('data/classes/train.txt')\n",
    "dev = readDataSet(\"data/classes/test.txt\")\n",
    "nwords = len(w2i)\n",
    "ntags = len(t2i)\n",
    "\n",
    "print(nwords,':',ntags)\n",
    "print('train[0] : \\n',train[0])\n",
    "print('test[0] : \\n',dev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets create the model and trainer\n",
    "# we are using the adam trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)\n",
    "\n",
    "# Create the parameters. \n",
    "W_sm = model.add_lookup_parameters((nwords,ntags)) # weights\n",
    "b_sm = model.add_parameters(ntags) # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets write a method to compute the weights once we know w and b\n",
    "def computeScores(words):\n",
    "    # renew the Computation graph\n",
    "    dy.renew_cg()\n",
    "    scores = dy.esum([dy.lookup(W_sm,x) for x in words])\n",
    "    biases = dy.parameter(b_sm)\n",
    "    return scores+biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration  0  the training loss is :  7359.954819768667  time taken :  0.3910384178161621\n",
      "At iteration  0  the test accuracy is :  34.52488687782805 %\n",
      "At iteration  1  the training loss is :  7185.740517809987  time taken :  0.3800036907196045\n",
      "At iteration  1  the test accuracy is :  34.43438914027149 %\n",
      "At iteration  2  the training loss is :  7017.566231377423  time taken :  0.3820023536682129\n",
      "At iteration  2  the test accuracy is :  34.660633484162894 %\n",
      "At iteration  3  the training loss is :  6861.6886631548405  time taken :  0.37200212478637695\n",
      "At iteration  3  the test accuracy is :  34.47963800904977 %\n",
      "At iteration  4  the training loss is :  6711.6247884482145  time taken :  0.37504005432128906\n",
      "At iteration  4  the test accuracy is :  34.705882352941174 %\n",
      "At iteration  5  the training loss is :  6567.915987864137  time taken :  0.3679540157318115\n",
      "At iteration  5  the test accuracy is :  34.705882352941174 %\n",
      "At iteration  6  the training loss is :  6432.217577777803  time taken :  0.36844778060913086\n",
      "At iteration  6  the test accuracy is :  34.751131221719454 %\n",
      "At iteration  7  the training loss is :  6304.308162353933  time taken :  0.39053940773010254\n",
      "At iteration  7  the test accuracy is :  35.1131221719457 %\n",
      "At iteration  8  the training loss is :  6181.755029063672  time taken :  0.3864927291870117\n",
      "At iteration  8  the test accuracy is :  35.1131221719457 %\n",
      "At iteration  9  the training loss is :  6066.276900500059  time taken :  0.37595105171203613\n",
      "At iteration  9  the test accuracy is :  34.751131221719454 %\n",
      "At iteration  10  the training loss is :  5955.208631712943  time taken :  0.38454508781433105\n",
      "At iteration  10  the test accuracy is :  34.751131221719454 %\n",
      "At iteration  11  the training loss is :  5844.3905066773295  time taken :  0.3670015335083008\n",
      "At iteration  11  the test accuracy is :  34.841628959276015 %\n",
      "At iteration  12  the training loss is :  5746.845968015492  time taken :  0.36350393295288086\n",
      "At iteration  12  the test accuracy is :  35.248868778280546 %\n",
      "At iteration  13  the training loss is :  5645.75820286572  time taken :  0.39595699310302734\n",
      "At iteration  13  the test accuracy is :  35.47511312217195 %\n",
      "At iteration  14  the training loss is :  5554.308657459915  time taken :  0.36150383949279785\n",
      "At iteration  14  the test accuracy is :  35.83710407239819 %\n",
      "At iteration  15  the training loss is :  5461.61496552825  time taken :  0.3810007572174072\n",
      "At iteration  15  the test accuracy is :  35.83710407239819 %\n",
      "At iteration  16  the training loss is :  5378.701389759779  time taken :  0.37199854850769043\n",
      "At iteration  16  the test accuracy is :  35.70135746606335 %\n",
      "At iteration  17  the training loss is :  5296.51099152863  time taken :  0.38750553131103516\n",
      "At iteration  17  the test accuracy is :  35.339366515837106 %\n",
      "At iteration  18  the training loss is :  5210.012936115265  time taken :  0.3705008029937744\n",
      "At iteration  18  the test accuracy is :  35.74660633484163 %\n",
      "At iteration  19  the training loss is :  5133.77210906893  time taken :  0.3839876651763916\n",
      "At iteration  19  the test accuracy is :  36.15384615384615 %\n",
      "At iteration  20  the training loss is :  5061.564982440323  time taken :  0.3665025234222412\n",
      "At iteration  20  the test accuracy is :  35.79185520361991 %\n",
      "At iteration  21  the training loss is :  4990.528957955539  time taken :  0.38039278984069824\n",
      "At iteration  21  the test accuracy is :  35.52036199095023 %\n",
      "At iteration  22  the training loss is :  4915.759946249425  time taken :  0.36396265029907227\n",
      "At iteration  22  the test accuracy is :  35.79185520361991 %\n",
      "At iteration  23  the training loss is :  4850.481745231897  time taken :  0.38654518127441406\n",
      "At iteration  23  the test accuracy is :  35.79185520361991 %\n",
      "At iteration  24  the training loss is :  4785.618699610233  time taken :  0.3700075149536133\n",
      "At iteration  24  the test accuracy is :  35.70135746606335 %\n"
     ]
    }
   ],
   "source": [
    "# Now lets perform the the training\n",
    "for i in range(25):\n",
    "    # Perform the shuffling of the training data\n",
    "    random.shuffle(train)\n",
    "    \n",
    "    # initialize the training loss and time\n",
    "    startTime = time.time()\n",
    "    trainLoss = 0\n",
    "    \n",
    "    # train\n",
    "    for words,tag in train:\n",
    "        loss = dy.pickneglogsoftmax(computeScores(words=words),tag)\n",
    "        trainLoss = trainLoss+loss.value()\n",
    "        \n",
    "        # compute gradients and update the parameters\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print('At iteration ',i,' the training loss is : ',trainLoss,' time taken : ',(time.time()-startTime))\n",
    "    \n",
    "    # test\n",
    "    testCorrect = 0\n",
    "    for words,tag in dev:\n",
    "        scores = computeScores(words=words).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        if(predict == tag):\n",
    "            testCorrect = testCorrect + 1\n",
    "    print('At iteration ',i,' the test accuracy is : ',(testCorrect/len(dev))*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
